{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this project, we will attempt to build a chacarter-level GPT language model which learnes to add two non-negative integers, i.e. given the input string \"a+b=c\", the model will be trained to predict the next character following a sliding context window.\n",
    "\n",
    "#### This is a simple next character prediction task. We will attempt two different versions of this task: 1) The integers of \"c\" are predicted left-to-right 2) the integers are predicted from right to left (i.e backward) which is typically how humans compute additions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['+', '0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', '<*>', '<PAD>', '=']\n",
      "vocab_size = 15\n",
      "{'+': 0, '0': 1, '1': 2, '10': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, '<*>': 12, '<PAD>': 13, '=': 14}\n"
     ]
    }
   ],
   "source": [
    "# first let's set up the token vocabulary for this problem\n",
    "# note that we have two special tokens '<*>' which denotes the beginning or end of a \n",
    "# sequence and the '<PAD>' token which is used for pre-padding sequences to ensure fixed length \n",
    "vocab = sorted(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '+', '=', '<*>', '<PAD>'])\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary: {vocab}\")\n",
    "print(f\"vocab_size = {vocab_size}\")\n",
    "\n",
    "# tokenization\n",
    "ctoi = {vocab[i]:i for i in range(vocab_size)}\n",
    "itoc = {i:vocab[i] for i in range(vocab_size)}\n",
    "encode = lambda s: [ctoi[c] for c in s]  # converts a string to integer token sequence\n",
    "decode = lambda s: [itoc[ix] for ix in s]  # converts an integer token sequence to string of characters\n",
    "print(ctoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets implement the data loader which generates a batch of input-target pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1223)\n",
    "\n",
    "max_digits = 5 # max number of digits for input integers 'a' and 'b'\n",
    "batch_size = 1\n",
    "block_size = 15 # size of context window\n",
    "\n",
    "# generates input target pairs for a single problem string \"a+b=c\"\n",
    "def generate_problem(max_digits, block_size, backward=False):\n",
    "\n",
    "    max_size = max(3*max_digits, 2*block_size)+1\n",
    "\n",
    "    # randomly generate two integers\n",
    "    a = random.randint(0,10**max_digits-1)\n",
    "    b = random.randint(0,10**max_digits-1)\n",
    "    c = a + b\n",
    "\n",
    "    prompt = list(f\"{a}+{b}=\")\n",
    "    answer = list(f\"{c}\")\n",
    "    \n",
    "    print(answer)\n",
    "    if backward:\n",
    "        # reverse the digits of \"c\"\n",
    "        answer = reversed(answer)\n",
    "\n",
    "    print(f\"prompt: {prompt}\")\n",
    "    print(f\"answer: {answer}\")\n",
    "\n",
    "    # encolse with special token\n",
    "    prompt = ['<*>'] + prompt\n",
    "    answer = answer + ['<*>'] \n",
    "    problem = prompt+answer\n",
    "    tot_len = len(problem)\n",
    "\n",
    "    # pre-pad the problem string to make it max_size long\n",
    "    problem = ['<PAD>']*(max_size-tot_len) + problem\n",
    "    \n",
    "    print(f\"padded problem: {problem}\")\n",
    "    \n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(max_size-block_size):\n",
    "        context = problem[i:i+block_size] \n",
    "        target = problem[i+1:i+block_size+1]\n",
    "        \n",
    "        # tokenize the sequences\n",
    "        #context = [ctoi[c] for c in context]\n",
    "        #target = ctoi[target]\n",
    "\n",
    "        contexts.append(context)\n",
    "        targets.append(target)    \n",
    "        print(f\"context: {context} -- > target: {target}\")\n",
    "\n",
    "    # create pytorch tensors of tokenized input and target batch\n",
    "    x, y, = None, None\n",
    "    #x = torch.tensor(contexts).to(device)\n",
    "    #y = torch.tensor(targets).to(device)\n",
    "\n",
    "    return max_size, x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '4', '7', '0', '2']\n",
      "prompt: ['5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=']\n",
      "answer: ['1', '2', '4', '7', '0', '2']\n",
      "padded problem: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4', '7', '0', '2', '<*>']\n",
      "context: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4'] -- > target: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5']\n",
      "context: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5'] -- > target: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7']\n",
      "context: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7'] -- > target: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+']\n",
      "context: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+'] -- > target: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6']\n",
      "context: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6'] -- > target: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7']\n",
      "context: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7'] -- > target: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2']\n",
      "context: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2'] -- > target: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4']\n",
      "context: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4'] -- > target: ['<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5']\n",
      "context: ['<PAD>', '<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5'] -- > target: ['<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=']\n",
      "context: ['<PAD>', '<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '='] -- > target: ['<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1']\n",
      "context: ['<PAD>', '<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1'] -- > target: ['<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2']\n",
      "context: ['<*>', '5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2'] -- > target: ['5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4']\n",
      "context: ['5', '7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4'] -- > target: ['7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4', '7']\n",
      "context: ['7', '4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4', '7'] -- > target: ['4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4', '7', '0']\n",
      "context: ['4', '5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4', '7', '0'] -- > target: ['5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4', '7', '0', '2']\n",
      "context: ['5', '7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4', '7', '0', '2'] -- > target: ['7', '+', '6', '7', '2', '4', '5', '=', '1', '2', '4', '7', '0', '2', '<*>']\n"
     ]
    }
   ],
   "source": [
    "max_size, x, y = generate_problem(max_digits, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
